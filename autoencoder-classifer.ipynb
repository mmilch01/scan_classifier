{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n@author: mmilchenko\\n'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "import getpass, ipywidgets as ipw, os, json, shlex, io, re, tempfile, subprocess,unittest\n",
    "import pydicom,numpy as np,csv,warnings,pickle,sys,tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from IPython.display import FileLink\n",
    "from matplotlib import pyplot as plt\n",
    "from zipfile import ZipFile\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from juxnat_lib.xnat_utils import *\n",
    "from autoencoder_classifier import DICOMAutoencoderModel\n",
    "\n",
    "\"\"\"\n",
    "@author: mmilchenko\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting test/autoencoder.256.20K_tokens.09252023.zip\n",
      "loading vocabulary from test/autoencoder.256.20K_tokens.09252023\n",
      "Vocabulary loaded:  test/autoencoder.256.20K_tokens.09252023\n",
      "loading mdoel from test/autoencoder.256.20K_tokens.09252023.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daem=DICOMAutoencoderModel()\n",
    "daem.load_model_autoencoder('test/autoencoder.256.20K_tokens.09252023.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "daem.model_autoencoder=daem.get_model(len(daem.vectorizer.get_vocabulary()),base_layer_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7f07e010f2b0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daem.vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f09a0956400>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daem.autoencoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: \n",
    "#1. load spreadsheet with pre-existing nomenclature\n",
    "#2. collect DICOM's from that nomenclature\n",
    "#3. create arrays 'descs' from those scans\n",
    "#4. simultaneously, create array with assigned type\n",
    "#5. generate classifier model\n",
    "#6. run testing/classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['xnat_imagescandata_id', 'frames', 'series_description', 'ID', 'type', 'URI', 'subject', 'experiment', 'hof_id'])\n"
     ]
    }
   ],
   "source": [
    "#1. load spreadsheet with pre-existing nomenclature.\n",
    "import csv\n",
    "def csv_to_dict(filename):\n",
    "    with open(filename, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        data_dict = {field: [] for field in reader.fieldnames}\n",
    "        for row in reader:\n",
    "            for field in reader.fieldnames:\n",
    "                data_dict[field].append(row[field])\n",
    "    return data_dict\n",
    "\n",
    "# Example usage:\n",
    "filename = '/home/mmilchenko/src/scan_classifier/test/all_scans_hofid.csv'\n",
    "scans = csv_to_dict(filename)\n",
    "print(scans.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n"
     ]
    }
   ],
   "source": [
    "print(scans['ID'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    32  100    32    0     0    159      0 --:--:-- --:--:-- --:--:--   160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n"
     ]
    }
   ],
   "source": [
    "sp=ServerParams(server='https://cnda.wustl.edu', user='mmilch', password='abc234BB', project='I3CR')\n",
    "if sp.connect():\n",
    "    print('connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td='/home/mmilchenko/src/scan_classifier/test/dcm'\n",
    "\n",
    "xi=XnatIterator(sp); xi.verbosity=0\n",
    "for i in range(10000,100000): #len(scans['URI')\n",
    "    try:\n",
    "        name_rt=scans['subject'][i]+'_'+scans['experiment'][i]+'_'+scans['ID'][i]\n",
    "        #h=tempfile.NamedTemporaryFile(); temp=h.name; h.close()    \n",
    "        print('listing files for',name_rt)\n",
    "        files=xi.list_scan_files(scans['subject'][i],scans['experiment'][i],scans['ID'][i])    \n",
    "        print('downloading first file')\n",
    "        ff=td+'/'+name_rt+'.full.dcm'    \n",
    "        xi.curl_download_single_file(files[0],ff)    \n",
    "        \n",
    "        #targ_filename='{}/{:06d}.dcm'.format(td,i)\n",
    "        #xi.curl_download_single_file(scans['URI'][i]+,targ_filename)\n",
    "        \n",
    "        print('reading',ff)\n",
    "        ds=pydicom.filereader.dcmread(ff,stop_before_pixels=True,specific_tags=daem._all_tags)\n",
    "        ft='{}/{:06d}_{}.dcm'.format(td,i,name_rt)\n",
    "        print('writing',ft)\n",
    "        pydicom.filewriter.dcmwrite(ft,ds)\n",
    "        os.remove(ff)\n",
    "    except Exception as e:\n",
    "        print('WARNING: file 0 is missing for scan:',name_rt)\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file 0\n",
      "reading file 10000\n",
      "reading file 20000\n",
      "reading file 30000\n",
      "writing file /home/mmilchenko/src/scan_classifier/test/all_scans_hofid.pkl.pkl\n"
     ]
    }
   ],
   "source": [
    "#3.Create the array 'descs' from those scans.\n",
    "scans_list=daem.generate_scanlist(td,out_file='/home/mmilchenko/src/scan_classifier/test/all_scans_hofid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def reorder_labels(directory_name, label_array):\n",
    "    # Get list of all files in directory\n",
    "    files = [f for f in os.listdir(directory_name) if os.path.isfile(os.path.join(directory_name, f))]\n",
    "    \n",
    "    # Extract the six-digit numbers from file names using regex\n",
    "    file_numbers = [int(re.match(r'(\\d{6})_', f).group(1)) for f in files if re.match(r'(\\d{6})_', f)]\n",
    "    \n",
    "    # Sort files based on their numbers\n",
    "    sorted_file_numbers = sorted(file_numbers)\n",
    "    \n",
    "    # Create a new label array using the sorted file numbers\n",
    "    new_label_array = [label_array[num] for num in sorted_file_numbers]\n",
    "    \n",
    "    return new_label_array\n",
    "\n",
    "scan_types=reorder_labels(td,scans['hof_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OT'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[\"CBF\", \"CBV\", \"DSC\", \"DWI\", \"FA\", \"MD\", \"MPRAGE\", \"MTT\", \"OT\", \"PBP\", \"SWI\", \"T1hi\", \"T1lo\", \"T2FLAIR\", \"T2hi\", \"T2lo\", \"TRACEW\", \"TTP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(daem.vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data.\n",
    "descs=daem.prepare_descs(scans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AngioFlag_N BodyPartExamined_BRAIN ImageType0_ORIGINAL ImageType1_PRIMARY ImageType2_FMRI ImageType3_NONE ImageType4_ND ImageType5_MOSAIC InPlanePhaseEncodingDirection_COL MRAcquisitionType_2D Manufacturer_SIEMENS ManufacturerModelName_Skyra Modality_MR PatientPosition_HFS PhotometricInterpretation_MONOCHROME2 ScanOptions0_F ScanOptions1_S ScanningSequence0_E ScanningSequence1_P SequenceName_*epfid2d1_94 SequenceVariant0_S SequenceVariant1_K SeriesDescription_REST1 StudyDescription_I3CR TransmitCoilName_Body VariableFlipAngleFlag_N WindowCenterWidthExplanation0_A WindowCenterWidthExplanation1_l WindowCenterWidthExplanation2_g WindowCenterWidthExplanation3_o WindowCenterWidthExplanation4_1'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, all_possible_labels):\n",
    "    # Initialize the one-hot encoded list\n",
    "    encoded_list = []\n",
    "\n",
    "    # For each label in the input labels\n",
    "    for label in labels:\n",
    "        # Create a one-hot encoded vector for the label\n",
    "        encoded_vector = [1 if label == possible_label else 0 for possible_label in all_possible_labels]\n",
    "        \n",
    "        # Append the one-hot encoded vector to the list\n",
    "        encoded_list.append(encoded_vector)\n",
    "\n",
    "    return encoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 31.177443197372025\n"
     ]
    }
   ],
   "source": [
    "n,sum,mx=0,0,0\n",
    "for desc in descs:\n",
    "    l=len(desc.split(' '))\n",
    "    mx=l if l>mx else mx\n",
    "    sum+=len(desc.split(' '))\n",
    "    n+=1\n",
    "print (mx,sum/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descs[10000].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels=one_hot_encode(scan_types,[\"CBF\", \"CBV\", \"DSC\", \"DWI\", \"FA\", \"MD\", \"MPRAGE\", \"MTT\", \"OT\", \"PBP\", \"SWI\", \"T1hi\", \"T1lo\", \"T2FLAIR\", \"T2hi\", \"T2lo\", \"TRACEW\", \"TTP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text,label):\n",
    "    return daem.vectorizer(text),label\n",
    "\n",
    "batch_size=64\n",
    "#create a tf.data.Dataset object, to be used for training.\n",
    "ds = tf.data.Dataset.from_tensor_slices((descs,encoded_labels))\n",
    "ds = ds.batch(batch_size)  # Define your batch size here\n",
    "ds = ds.map(vectorize_text)\n",
    "dict_size=len(daem.vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(20000,), dtype=float32, numpy=array([1., 1., 1., ..., 0., 0., 0.], dtype=float32)>,\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_text(descs[0],encoded_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " encoder_input (Dense)       (None, 256)               5120256   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " encoder_output (Dense)      (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 18)                2322      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,170,034\n",
      "Trainable params: 5,170,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model=daem.get_classifier_model(daem.autoencoder_model, len(classes), max_tokens=len(daem.vectorizer.get_vocabulary()),hidden_layer_size=512)\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "563/571 [============================>.] - ETA: 0s - loss: 0.5587 - accuracy: 0.8660 - categorical_accuracy: 0.8660INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 5s 7ms/step - loss: 0.5769 - accuracy: 0.8612 - categorical_accuracy: 0.8612\n",
      "Epoch 2/100\n",
      "562/571 [============================>.] - ETA: 0s - loss: 0.2501 - accuracy: 0.9255 - categorical_accuracy: 0.9255INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2719 - accuracy: 0.9201 - categorical_accuracy: 0.9201\n",
      "Epoch 3/100\n",
      "564/571 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9301 - categorical_accuracy: 0.9301INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2487 - accuracy: 0.9254 - categorical_accuracy: 0.9254\n",
      "Epoch 4/100\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.9298 - categorical_accuracy: 0.9298INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2404 - accuracy: 0.9277 - categorical_accuracy: 0.9277\n",
      "Epoch 5/100\n",
      "565/571 [============================>.] - ETA: 0s - loss: 0.2192 - accuracy: 0.9330 - categorical_accuracy: 0.9330INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2333 - accuracy: 0.9296 - categorical_accuracy: 0.9296\n",
      "Epoch 6/100\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9322 - categorical_accuracy: 0.9322INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 4s 7ms/step - loss: 0.2300 - accuracy: 0.9302 - categorical_accuracy: 0.9302\n",
      "Epoch 7/100\n",
      "570/571 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9314 - categorical_accuracy: 0.9314INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2269 - accuracy: 0.9313 - categorical_accuracy: 0.9313\n",
      "Epoch 8/100\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9323 - categorical_accuracy: 0.9323INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2241 - accuracy: 0.9323 - categorical_accuracy: 0.9323\n",
      "Epoch 9/100\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.2151 - accuracy: 0.9338 - categorical_accuracy: 0.9338INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2201 - accuracy: 0.9326 - categorical_accuracy: 0.9326\n",
      "Epoch 10/100\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9343 - categorical_accuracy: 0.9343INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2183 - accuracy: 0.9333 - categorical_accuracy: 0.9333\n",
      "Epoch 11/100\n",
      "561/571 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9389 - categorical_accuracy: 0.9389INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.9335 - categorical_accuracy: 0.9335\n",
      "Epoch 12/100\n",
      "560/571 [============================>.] - ETA: 0s - loss: 0.1931 - accuracy: 0.9398 - categorical_accuracy: 0.9398INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2156 - accuracy: 0.9339 - categorical_accuracy: 0.9339\n",
      "Epoch 13/100\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.9340 - categorical_accuracy: 0.9340INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 4s 6ms/step - loss: 0.2153 - accuracy: 0.9340 - categorical_accuracy: 0.9340\n",
      "Epoch 14/100\n",
      "565/571 [============================>.] - ETA: 0s - loss: 0.2001 - accuracy: 0.9379 - categorical_accuracy: 0.9379INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2130 - accuracy: 0.9344 - categorical_accuracy: 0.9344\n",
      "Epoch 15/100\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.2075 - accuracy: 0.9357 - categorical_accuracy: 0.9357INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 4s 6ms/step - loss: 0.2122 - accuracy: 0.9345 - categorical_accuracy: 0.9345\n",
      "Epoch 16/100\n",
      "562/571 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9398 - categorical_accuracy: 0.9398INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2103 - accuracy: 0.9347 - categorical_accuracy: 0.9347\n",
      "Epoch 17/100\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.2023 - accuracy: 0.9370 - categorical_accuracy: 0.9370INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2096 - accuracy: 0.9350 - categorical_accuracy: 0.9350\n",
      "Epoch 18/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2092 - accuracy: 0.9349 - categorical_accuracy: 0.9349\n",
      "Epoch 19/100\n",
      "560/571 [============================>.] - ETA: 0s - loss: 0.1870 - accuracy: 0.9407 - categorical_accuracy: 0.9407INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.9353 - categorical_accuracy: 0.9353\n",
      "Epoch 20/100\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.9354 - categorical_accuracy: 0.9354INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2076 - accuracy: 0.9354 - categorical_accuracy: 0.9354\n",
      "Epoch 21/100\n",
      "561/571 [============================>.] - ETA: 0s - loss: 0.1866 - accuracy: 0.9410 - categorical_accuracy: 0.9410INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2056 - accuracy: 0.9360 - categorical_accuracy: 0.9360\n",
      "Epoch 22/100\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 0.2048 - accuracy: 0.9358 - categorical_accuracy: 0.9358\n",
      "Epoch 23/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2048 - accuracy: 0.9358 - categorical_accuracy: 0.9358\n",
      "Epoch 24/100\n",
      "560/571 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.9419 - categorical_accuracy: 0.9419INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9365 - categorical_accuracy: 0.9365\n",
      "Epoch 25/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2038 - accuracy: 0.9362 - categorical_accuracy: 0.9362\n",
      "Epoch 26/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2033 - accuracy: 0.9363 - categorical_accuracy: 0.9363\n",
      "Epoch 27/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2027 - accuracy: 0.9365 - categorical_accuracy: 0.9365\n",
      "Epoch 28/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2029 - accuracy: 0.9363 - categorical_accuracy: 0.9363\n",
      "Epoch 29/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2022 - accuracy: 0.9364 - categorical_accuracy: 0.9364\n",
      "Epoch 30/100\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.9368 - categorical_accuracy: 0.9368INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2029 - accuracy: 0.9368 - categorical_accuracy: 0.9368\n",
      "Epoch 31/100\n",
      "570/571 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9368 - categorical_accuracy: 0.9368INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2020 - accuracy: 0.9368 - categorical_accuracy: 0.9368\n",
      "Epoch 32/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2024 - accuracy: 0.9366 - categorical_accuracy: 0.9366\n",
      "Epoch 33/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2032 - accuracy: 0.9367 - categorical_accuracy: 0.9367\n",
      "Epoch 34/100\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2032 - accuracy: 0.9365 - categorical_accuracy: 0.9365\n",
      "Epoch 35/100\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9396 - categorical_accuracy: 0.9396INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2016 - accuracy: 0.9370 - categorical_accuracy: 0.9370\n",
      "Epoch 36/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2041 - accuracy: 0.9366 - categorical_accuracy: 0.9366\n",
      "Epoch 37/100\n",
      "571/571 [==============================] - 3s 4ms/step - loss: 0.2027 - accuracy: 0.9366 - categorical_accuracy: 0.9366\n",
      "Epoch 38/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2036 - accuracy: 0.9367 - categorical_accuracy: 0.9367\n",
      "Epoch 39/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2023 - accuracy: 0.9365 - categorical_accuracy: 0.9365\n",
      "Epoch 40/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2028 - accuracy: 0.9367 - categorical_accuracy: 0.9367\n",
      "Epoch 41/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2030 - accuracy: 0.9364 - categorical_accuracy: 0.9364\n",
      "Epoch 42/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2041 - accuracy: 0.9368 - categorical_accuracy: 0.9368\n",
      "Epoch 43/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2029 - accuracy: 0.9363 - categorical_accuracy: 0.9363\n",
      "Epoch 44/100\n",
      "571/571 [==============================] - 3s 4ms/step - loss: 0.2043 - accuracy: 0.9359 - categorical_accuracy: 0.9359\n",
      "Epoch 45/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2031 - accuracy: 0.9367 - categorical_accuracy: 0.9367\n",
      "Epoch 46/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2052 - accuracy: 0.9362 - categorical_accuracy: 0.9362\n",
      "Epoch 47/100\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2048 - accuracy: 0.9368 - categorical_accuracy: 0.9368\n",
      "Epoch 48/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2082 - accuracy: 0.9368 - categorical_accuracy: 0.9368\n",
      "Epoch 49/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2064 - accuracy: 0.9369 - categorical_accuracy: 0.9369\n",
      "Epoch 50/100\n",
      "571/571 [==============================] - 3s 4ms/step - loss: 0.2059 - accuracy: 0.9368 - categorical_accuracy: 0.9368\n",
      "Epoch 51/100\n",
      "563/571 [============================>.] - ETA: 0s - loss: 0.1897 - accuracy: 0.9417 - categorical_accuracy: 0.9417INFO:tensorflow:Assets written to: /home/mmilchenko/temp/tensorboard/training/assets\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2053 - accuracy: 0.9372 - categorical_accuracy: 0.9372\n",
      "Epoch 52/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2073 - accuracy: 0.9368 - categorical_accuracy: 0.9368\n",
      "Epoch 53/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2071 - accuracy: 0.9365 - categorical_accuracy: 0.9365\n",
      "Epoch 54/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2081 - accuracy: 0.9364 - categorical_accuracy: 0.9364\n",
      "Epoch 55/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2077 - accuracy: 0.9364 - categorical_accuracy: 0.9364\n",
      "Epoch 56/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2066 - accuracy: 0.9367 - categorical_accuracy: 0.9367\n",
      "Epoch 57/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.9363 - categorical_accuracy: 0.9363\n",
      "Epoch 58/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2134 - accuracy: 0.9361 - categorical_accuracy: 0.9361\n",
      "Epoch 59/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2128 - accuracy: 0.9357 - categorical_accuracy: 0.9357\n",
      "Epoch 60/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2112 - accuracy: 0.9366 - categorical_accuracy: 0.9366\n",
      "Epoch 61/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2127 - accuracy: 0.9359 - categorical_accuracy: 0.9359\n",
      "Epoch 62/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2112 - accuracy: 0.9362 - categorical_accuracy: 0.9362\n",
      "Epoch 63/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2135 - accuracy: 0.9367 - categorical_accuracy: 0.9367\n",
      "Epoch 64/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9367 - categorical_accuracy: 0.9367\n",
      "Epoch 65/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2117 - accuracy: 0.9362 - categorical_accuracy: 0.9362\n",
      "Epoch 66/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2116 - accuracy: 0.9359 - categorical_accuracy: 0.9359\n",
      "Epoch 67/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2103 - accuracy: 0.9368 - categorical_accuracy: 0.9368\n",
      "Epoch 68/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2168 - accuracy: 0.9366 - categorical_accuracy: 0.9366\n",
      "Epoch 69/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2137 - accuracy: 0.9356 - categorical_accuracy: 0.9356\n",
      "Epoch 70/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2180 - accuracy: 0.9365 - categorical_accuracy: 0.9365\n",
      "Epoch 71/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2191 - accuracy: 0.9359 - categorical_accuracy: 0.9359\n",
      "Epoch 72/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2161 - accuracy: 0.9363 - categorical_accuracy: 0.9363\n",
      "Epoch 73/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2161 - accuracy: 0.9356 - categorical_accuracy: 0.9356\n",
      "Epoch 74/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2198 - accuracy: 0.9356 - categorical_accuracy: 0.9356\n",
      "Epoch 75/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2147 - accuracy: 0.9363 - categorical_accuracy: 0.9363\n",
      "Epoch 76/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2196 - accuracy: 0.9359 - categorical_accuracy: 0.9359\n",
      "Epoch 77/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2133 - accuracy: 0.9364 - categorical_accuracy: 0.9364\n",
      "Epoch 78/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2188 - accuracy: 0.9353 - categorical_accuracy: 0.9353\n",
      "Epoch 79/100\n",
      "571/571 [==============================] - 3s 6ms/step - loss: 0.2174 - accuracy: 0.9355 - categorical_accuracy: 0.9355\n",
      "Epoch 80/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2153 - accuracy: 0.9357 - categorical_accuracy: 0.9357\n",
      "Epoch 81/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2178 - accuracy: 0.9358 - categorical_accuracy: 0.9358\n",
      "Epoch 82/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2197 - accuracy: 0.9362 - categorical_accuracy: 0.9362\n",
      "Epoch 83/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2200 - accuracy: 0.9358 - categorical_accuracy: 0.9358\n",
      "Epoch 84/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2191 - accuracy: 0.9362 - categorical_accuracy: 0.9362\n",
      "Epoch 85/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2209 - accuracy: 0.9356 - categorical_accuracy: 0.9356\n",
      "Epoch 86/100\n",
      "571/571 [==============================] - 4s 6ms/step - loss: 0.2257 - accuracy: 0.9351 - categorical_accuracy: 0.9351\n",
      "Epoch 87/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2268 - accuracy: 0.9353 - categorical_accuracy: 0.9353\n",
      "Epoch 88/100\n",
      "571/571 [==============================] - 2s 3ms/step - loss: 0.2215 - accuracy: 0.9356 - categorical_accuracy: 0.9356\n",
      "Epoch 89/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2200 - accuracy: 0.9353 - categorical_accuracy: 0.9353\n",
      "Epoch 90/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2262 - accuracy: 0.9350 - categorical_accuracy: 0.9350\n",
      "Epoch 91/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2220 - accuracy: 0.9352 - categorical_accuracy: 0.9352\n",
      "Epoch 92/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2304 - accuracy: 0.9348 - categorical_accuracy: 0.9348\n",
      "Epoch 93/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2213 - accuracy: 0.9351 - categorical_accuracy: 0.9351\n",
      "Epoch 94/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2202 - accuracy: 0.9354 - categorical_accuracy: 0.9354\n",
      "Epoch 95/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2240 - accuracy: 0.9350 - categorical_accuracy: 0.9350\n",
      "Epoch 96/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2250 - accuracy: 0.9347 - categorical_accuracy: 0.9347\n",
      "Epoch 97/100\n",
      "571/571 [==============================] - 3s 5ms/step - loss: 0.2258 - accuracy: 0.9352 - categorical_accuracy: 0.9352\n",
      "Epoch 98/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2251 - accuracy: 0.9346 - categorical_accuracy: 0.9346\n",
      "Epoch 99/100\n",
      "571/571 [==============================] - 3s 4ms/step - loss: 0.2260 - accuracy: 0.9352 - categorical_accuracy: 0.9352\n",
      "Epoch 100/100\n",
      "571/571 [==============================] - 2s 4ms/step - loss: 0.2361 - accuracy: 0.9340 - categorical_accuracy: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0543862340>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier_model.optimizer.learning_rate.assign(0.0001)\n",
    "classifier_model.fit(ds,epochs=100, callbacks=[keras.callbacks.ModelCheckpoint(filepath='/home/mmilchenko/temp/tensorboard/training',save_best_only=True,monitor='categorical_accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
