{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, ipywidgets as ipw, os, json, shlex, io, re, tempfile, subprocess,unittest\n",
    "import datetime\n",
    "import pydicom,numpy as np,csv,warnings,pickle,sys,tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import FileLink, JSON\n",
    "from io import BytesIO\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%tb\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from juxnat_lib.xnat_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from universal_scan_classifier import *\n",
    "#from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScanClassificationModelGUI(FrontDesk):\n",
    "    def __init__(self):        \n",
    "       \n",
    "        #plumbing objects\n",
    "        self._scm=ScanClassificationModel()\n",
    "    \n",
    "        ######################################################################\n",
    "        #define interface elements\n",
    "        layout=ipw.Layout(margin='0 100pt 0 0')\n",
    "        layout1=ipw.Layout(justify_content='center')\n",
    "        st={'description_width':'initial'}\n",
    "                \n",
    "        #User types in the nomenclature (scan types), comma separated\n",
    "        self._txt_scan_types=ipw.Text(value=\"MPRAGE,T1hi,SWI,T2lo,T1lo,DWI,T2FLAIR,T2hi,DSC,GRE_qBOLD,DWI_FRAME1,DWI_PART2,TRACEW,FA,FA_WU,MD,MD_WU,DSC_FRAME1,MTT,MTT_WU,CBV,CBV_WU,CBF,CBF_WU,PBP,TTP\", description='Scan types, comma separated:',\n",
    "                            layout={'width':'400pt'}, style=st, disabled=False)\n",
    "        self._txt_scan_types.observe(self._on_change_scan_types)\n",
    "        self._on_change_scan_types(self._txt_scan_types)\n",
    "        \n",
    "        #dropdown with all available DICOM tags.\n",
    "        self._drop_taglist=ipw.Dropdown(options=self._scm._supported_tags,description=\\\n",
    "                             'Available DICOM tags:',style=st,layout={'width':'300pt'})\n",
    "        \n",
    "        self._drop_taglist_xnat=ipw.Dropdown(options=self._scm._supported_tags_xnat,description=\\\n",
    "                             'Available XNAT fields:',style=st,layout={'width':'300pt'})\n",
    "\n",
    "        #button to add active DICOM tag from the list, to the list of tags that go into the model.\n",
    "        self._btn_addtag=ipw.Button(description=\"Add\",style={},layout={'width':'200pt'})\n",
    "        self._btn_addtag_xnat=ipw.Button(description=\"Add\",style={},layout={'width':'200pt'})\n",
    "        self._btn_addtag.on_click(self._addtag) #done\n",
    "        self._btn_addtag_xnat.on_click(self._addtag_xnat)\n",
    "        \n",
    "        #clear all DICOM tags, start over (easier than add/remove etc buttons)\n",
    "        self._btn_clearall=ipw.Button(description=\"Clear DICOM tags\",style={},layout={'width':'200pt'})\n",
    "        self._btn_clearall.on_click(self._cleartags) #done\n",
    "\n",
    "        self._btn_clearall_xnat=ipw.Button(description=\"Clear XNAT fields\",style={},layout={'width':'200pt'})\n",
    "        self._btn_clearall_xnat.on_click(self._cleartags_xnat) #done\n",
    "        \n",
    "        #a box listing currently selected DICOM tags.\n",
    "        self._tag_btn_box=ipw.HBox([self._btn_addtag,self._btn_clearall])\n",
    "        self._txt_used_tags=ipw.Textarea(value='', description='Used DICOM tags:', disabled=True,style=st)\n",
    "        \n",
    "        self._tag_xnat_btn_box=ipw.HBox([self._btn_addtag_xnat,self._btn_clearall_xnat])\n",
    "        self._txt_used_tags_xnat=ipw.Textarea(value='', description='Used XNAT fields:', disabled=True,style=st)\n",
    "\n",
    "        #nomenclature definition name (DICOM tags+ontology)\n",
    "        self._txt_nomenclature_name=ipw.Text(value=\"NeuroOncologyMRI\", description='Nomenclature name:',\n",
    "                            layout={'width':'200pt'}, style=st, disabled=False)\n",
    "        self._txt_nomenclature_name.observe(self._on_change_nomenclature_name)\n",
    "        self._on_change_nomenclature_name(self._txt_nomenclature_name)\n",
    "        \n",
    "        #button save the nomenclature definition to a json file\n",
    "        self._btn_save=ipw.Button(description=\"Save definition\",style={},layout={'width':'200pt'})\n",
    "        self._btn_save.on_click(self._save) #in process\n",
    "        \n",
    "        #button load the nomenclature definition from a json file\n",
    "        self._btn_load=ipw.FileUpload(accept='.json',\\\n",
    "                        multiple=False,style={},layout={'width':'200pt'})\n",
    "        #ipw.Button(description=\"Load definition\",style={},layout={'width':'200pt'})\n",
    "        self._btn_load.observe(self._load, names='value')\n",
    "        #self._btn_load.on_click(self._load) #in process\n",
    "        \n",
    "        #box containing load and save buttons.\n",
    "        self._loadsave_btn_box=ipw.HBox([self._btn_save,self._btn_load])\n",
    "        \n",
    "        #file link output\n",
    "        self._file_lnk_out=ipw.Output()\n",
    "        self._out_log = ipw.Output()\n",
    "        self._out_json = ipw.Output()\n",
    "        \n",
    "        #box containing all elements of nomenclature definition page.\n",
    "        #name must be 'main_box' to be visible to the GUIPages()\n",
    "        \n",
    "        ###########################################\n",
    "        # split GUI for DICOM tags and XNAT fields.\n",
    "        dcm_tag_box=ipw.VBox([self._drop_taglist, self._tag_btn_box, self._txt_used_tags])\n",
    "        xnat_field_box=ipw.VBox([self._drop_taglist_xnat, \\\n",
    "                                 self._tag_xnat_btn_box, self._txt_used_tags_xnat])\n",
    "        \n",
    "        acc_titles=['Add DICOM tags','Add XNAT fields']\n",
    "        acc=ipw.Accordion(children=[dcm_tag_box, xnat_field_box],selected_index=None)\n",
    "        for i in range(0,2): acc.set_title(i,acc_titles[i])\n",
    "        ############# end accordion setup #########\n",
    "\n",
    "        self.main_box=ipw.VBox([self._txt_nomenclature_name,self._txt_scan_types,\n",
    "                                acc,self._loadsave_btn_box, self._file_lnk_out,self._out_log,self._out_json])\n",
    "        \n",
    "        self._tempfile = None\n",
    "\n",
    "    def _on_change_nomenclature_name(self,b):        \n",
    "        self._scm._nomenclature_name=self._txt_nomenclature_name.value        \n",
    "        \n",
    "    def _addtag(self,b):\n",
    "        '''\n",
    "        add current DICOM tag from the list of tags (self._drop_taglist) to the chosen tag list.\n",
    "        '''\n",
    "        if self._drop_taglist.value not in self._scm._selected_tags:\n",
    "            self._scm._selected_tags.append(self._drop_taglist.value)\n",
    "            self._refresh_txt_used_tags()\n",
    "            \n",
    "    def _addtag_xnat(self,b):\n",
    "        if self._drop_taglist_xnat.value not in self._scm._selected_fields_xnat:\n",
    "            self._scm._selected_fields_xnat.append(self._drop_taglist_xnat.value)\n",
    "            self._refresh_txt_used_tags_xnat()\n",
    "        pass\n",
    "        \n",
    "    def _on_change_scan_types(self,b):\n",
    "        try:\n",
    "            self._scm._scan_types=sorted(self._txt_scan_types.value.split(','))\n",
    "            #print (self._scm._scan_types)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    def get_selected_tags_group_element(self):\n",
    "        return [ ScanClassificationModel.tagname_to_group_element(t) for t in self._scm._selected_tags ]\n",
    "    \n",
    "        \n",
    "    def _refresh_txt_used_tags(self):\n",
    "        '''\n",
    "        update used tag list from the internal variable self._selected_tags\n",
    "        '''\n",
    "        val=''\n",
    "        for t in self._scm._selected_tags:\n",
    "            tag=pydicom.tag.Tag(pydicom.datadict.tag_for_keyword(t))\n",
    "            val+=t+' '+str(tag)+'\\n'\n",
    "        self._txt_used_tags.value=val\n",
    "        \n",
    "    def _refresh_txt_used_tags_xnat(self):\n",
    "        '''\n",
    "        update xnat field list from the internal variable self._selected_tags\n",
    "        '''\n",
    "        val=''\n",
    "        for t in self._scm._selected_fields_xnat:\n",
    "            val+=t+'\\n'\n",
    "        self._txt_used_tags_xnat.value=val\n",
    "        \n",
    "    def _cleartags(self,b):\n",
    "        '''\n",
    "        clear the selected tag list and text box.\n",
    "        '''        \n",
    "        self._scm.clear_selected_tags()\n",
    "        self._txt_used_tags.value=''\n",
    "        \n",
    "    def _cleartags_xnat(self,b):\n",
    "        self._scm.clear_selected_fields_xnat()\n",
    "        self._txt_used_tags_xnat.value=''\n",
    "            \n",
    "    def _save(self,b):\n",
    "        '''\n",
    "        save nomenclature definition (selected DICOM tags, XNAT fields and scan types in a json file)\n",
    "        '''\n",
    "        if not self._scm.check_validity():\n",
    "            print (\"Invalid input, cannot save\")\n",
    "            return\n",
    "        \n",
    "        d=dict()\n",
    "        d['scan_types']=self._scm._scan_types\n",
    "        d['selected_dcm_tags']=self._scm._selected_tags\n",
    "        d['selected_fields_xnat']=self._scm._selected_fields_xnat\n",
    "        d['nomenclature_name']=self._scm._nomenclature_name\n",
    "        \n",
    "        #save to temp json file\n",
    "        try:\n",
    "            os.mkdir('./temp')\n",
    "        except:\n",
    "            pass\n",
    "        self._tempfile=tempfile.NamedTemporaryFile(dir='./temp',mode='w',prefix='nomenclature',suffix='.json')\n",
    "        with open(self._tempfile.name,'w') as fp: \n",
    "            json.dump(d,fp)\n",
    "            \n",
    "        #display file link\n",
    "        out=self._file_lnk_out\n",
    "        out.outputs=(); lnk=FileLink('temp/'+os.path.basename(self._tempfile.name))\n",
    "        with out: display(lnk)\n",
    "\n",
    "    def refresh(self):\n",
    "        self.enable_nav_prev(False)            \n",
    "    \n",
    "    def _load(self,b):        \n",
    "        '''\n",
    "        load nomenclature definition (selected DICOM tags and scan types in a json file)\n",
    "        '''\n",
    "        with self._out_log: \n",
    "            print('_load triggered')\n",
    "            try:\n",
    "                fupl=self._btn_load.value\n",
    "                files=list(fupl)\n",
    "                if len(files)<1: return\n",
    "                #print(files[0])\n",
    "                d=json.loads(bytes(files[0]['content']).decode('utf-8'))\n",
    "                self._scm.load(d)\n",
    "                self._txt_scan_types.value=','.join(sorted(d['scan_types']))\n",
    "                self._txt_nomenclature_name.value=d['nomenclature_name']    \n",
    "                self._refresh_txt_used_tags()\n",
    "                self._refresh_txt_used_tags_xnat()\n",
    "                print('nomenclature uploaded')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "class DataSelector(FrontDesk):\n",
    "    def __init__(self,serialize_file,classifier_model):\n",
    "        #scans read from uploaded files\n",
    "        self.scans_unclassified,self.scans_classified=self.scans_unclassified_compressed=[],[]\n",
    "        \n",
    "        \n",
    "        #file name or other description of test, train and validation set sources\n",
    "        self.test_src=self.train_src=self.val_src='None'\n",
    "                \n",
    "        self._classifier_model=classifier_model\n",
    "        self._connected=False\n",
    "        self._serialize_file=serialize_file\n",
    "        st={'description_width':'initial'}\n",
    "        layout=ipw.Layout(margin='0 100pt 0 0')\n",
    "        layout1=ipw.Layout(justify_content='center')\n",
    "        \n",
    "        self.sp=ServerParams()\n",
    "        self.sp.serialize(serialize_file,{},True)\n",
    "                \n",
    "        \n",
    "        ###################################\n",
    "        #GUI elements for XNAT login.\n",
    "        self.text1=ipw.Text(value=self.sp.server, description='XNAT server:', \n",
    "                            layout={'width':'200pt'}, style=st, disabled=False)\n",
    "#        self.text1=ipw.Text(value='https://cnda.wustl.edu', description='XNAT server:',\n",
    "#                            layout={'width':'200pt'}, style=st, disabled=False)\n",
    "\n",
    "        self.text2=ipw.Text(value=self.sp.user,description='user:',\n",
    "                                disabled=False, style=st, layout={'width':'100pt'})\n",
    "        self.text3=ipw.Password(value='',description='password:',\n",
    "                                disabled=False, style=st, layout={'width':'100pt'})\n",
    "        self.lbl1=ipw.Label('status: not connected', layout={'width':'120pt'}, style=st) #layout={'width':'240px','justify-content':'center'}\n",
    "        lbl2=ipw.Label('',layout={'width':'120pt'},style=st)\n",
    "        \n",
    "        self._project_text=ipw.Text(value=self.sp.project,description=\"XNAT project:\",disabled=False,style=st,\\\n",
    "                           layout={'width':'120pt'})\n",
    "        self._project_text.observe(self._change_project)\n",
    "        \n",
    "        self.btn1=ipw.Button(description=\"connect\",style={},layout={'width':'200pt'})        \n",
    "        self.btn1.on_click(self.on_connect)                        \n",
    "        vb1=ipw.HBox([self.text1,self.text2,self.text3])        \n",
    "        vb2=ipw.HBox([self.btn1,lbl2,self.lbl1])        \n",
    "        \n",
    "        #print('project:',self.sp.project)\n",
    "        \n",
    "        self.xnat_login_box=ipw.VBox([vb1,self._project_text,vb2])\n",
    "        \n",
    "        self._xi=XnatIterator(self.sp)\n",
    "        \n",
    "        \n",
    "        lay1={'width':'200pt'}\n",
    "        lay2={'width':'250pt'}\n",
    "\n",
    "        ##########################################\n",
    "        # GUI elements to prepare a dataset\n",
    "        prep_lbl1=ipw.Label(value='1. Upload a csv with XNAT experiments, with Subject and Experiment columns',layout=lay1)\n",
    "        prep_upl1=ipw.FileUpload(accept='.csv',multiple=False)\n",
    "        self._upl1_status=ipw.Label(value='waiting for upload...',layout=lay1)\n",
    "        prep_upl1.observe(self.read_uploaded_file1)\n",
    "        self._fupl1_exp=prep_upl1\n",
    "        \n",
    "        prep_lbl3=ipw.Label(value='2. Generate tagged scan list',layout=lay1)\n",
    "        #prep_btn1=ipw.Button(description='Generate', layout=lay1)\n",
    "        #prep_btn1.on_click(self.collect_scans)\n",
    "        self._generate_output=ProcessWithTextProgress('Generate',\\\n",
    "                                                self.collect_scans)\n",
    "        prep_btn1=self._generate_output._btn_run\n",
    "        prep_btn1.disabled=False        \n",
    "        self._out_lnk=ipw.Output()\n",
    "        \n",
    "        prep_status=ipw.Label(value='waiting to generate...',layout=lay1)\n",
    "        prep_hb1=ipw.HBox([prep_lbl1,prep_upl1,self._upl1_status])\n",
    "        prep_vb2=ipw.VBox([prep_lbl3,prep_status,self._generate_output.main_box,self._out_lnk])\n",
    "        self._prep_box=ipw.VBox([self.xnat_login_box,prep_hb1,prep_vb2])\n",
    "        self._coll_status=prep_status\n",
    "        \n",
    "        ##############################################\n",
    "        # GUI elements to upload raw dataset\n",
    "        prep_lbl5=ipw.Label(value='Upload a csv with tagged scan list, scan type undefined', layout=lay2)\n",
    "        prep_upl2=ipw.FileUpload(accept='.csv',multiple=False)\n",
    "        prep_upl2.observe(self.read_uploaded_file2)\n",
    "        self._upl2_status=ipw.Label(value='waiting for upload...',layout=lay1)\n",
    "        self._upl_raw_box=ipw.HBox([prep_lbl5,prep_upl2,self._upl2_status])\n",
    "        self._fupl2_scans_unclassified=prep_upl2\n",
    "                \n",
    "        ##############################################\n",
    "        # GUI elements to download compressed raw\n",
    "        dlraw_lbl1=ipw.Label(value='Remove duplicates from the scan list (type undefined)', layout=lay2)\n",
    "        self._dlraw_lbl_current_file=ipw.Label(value='Current dataset: undefined',layout=lay2)\n",
    "        self._dlraw_btn=dlraw_btn1=ipw.Button(description='Generate',style={},layout={'width':'200pt'},disabled=True)\n",
    "        dlraw_btn1.on_click(self.on_compress_scans)\n",
    "        self._dlraw_lnk=ipw.Output()\n",
    "        self._dlraw_box=ipw.VBox([dlraw_lbl1,self._dlraw_lbl_current_file,dlraw_btn1,self._dlraw_lnk])\n",
    "\n",
    "        \n",
    "        ###########################################\n",
    "        # GUI elements to upload training dataset\n",
    "        train_lbl1=ipw.Label(value='Upload a csv with tagged scan list, scan type defined')\n",
    "        train_upl1=ipw.FileUpload(accept='.csv',multiple=False)\n",
    "        train_upl1.observe(self.read_uploaded_file3)\n",
    "        self._upl3_status=ipw.Label(value='waiting for upload...',layout=lay1)\n",
    "        self._train_box=ipw.HBox([train_lbl1,train_upl1,self._upl3_status])\n",
    "        self._fupl3_scans_classified=train_upl1\n",
    "        \n",
    "        ###########################################\n",
    "        # GUI put together.\n",
    "        titles=['Generate unlabeled scan list',\\\n",
    "                'Upload unlabeled scan list (testing set)',\\\n",
    "                'Generate unlabeled scan list, no duplicates','Upload pre-labeled scan list (training set)']\n",
    "        \n",
    "        acc=ipw.Accordion(children=[self._prep_box, self._upl_raw_box, self._dlraw_box,self._train_box],\\\n",
    "                          selected_index=None)\n",
    "        for i in range(0,4): acc.set_title(i,titles[i])\n",
    "\n",
    "            #'XNAT login (optional)',\n",
    "            #                                    'Prepare dataset (raw or training)',\n",
    "            #                                    'Upload labeled dataset (optional)'))\n",
    "        \n",
    "        ###continue here!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        self.main_box=ipw.VBox([acc])\n",
    "        self._verbosity=1\n",
    "        '''        \n",
    "        hc=HOF_Classifier()\n",
    "        hc.load_model_nn('./scan_classifier_nn.11.26.2019')\n",
    "        self.hof_classifier=hc\n",
    "        '''\n",
    "    def _change_project(self,b):\n",
    "        self.sp.project=self._project_text.value\n",
    "        #print('project:',self.sp.project)\n",
    "        \n",
    "    def on_connect(self,b):\n",
    "        #self._show_scanview(False)\n",
    "        self.lbl1.value='status: connecting...'\n",
    "        self.sp.server,self.sp.user,self.sp.password=self.text1.value,self.text2.value,self.text3.value\n",
    "        \n",
    "        if self.sp.connect():                    \n",
    "            self.lbl1.value='status: connected'\n",
    "            self.btn1.description='Reconnect'            \n",
    "            self._connected=True\n",
    "            #self.enable_nav_next(True)\n",
    "            self.sp.serialize(self._serialize_file,{},False)\n",
    "        else:\n",
    "            self.lbl1.value='status: connection failed'  \n",
    "            if self._verbosity>0:\n",
    "                print(self.sp.jsession)\n",
    "            self.enable_nav_next(False)    \n",
    "    \n",
    "    def _noxnat_callback(self,b):        \n",
    "        self.btn1.enabled=not b.value\n",
    "\n",
    "    def refresh(self):\n",
    "        self.enable_nav_prev(False)\n",
    "        \n",
    "    def show_file_link(self,out,file):\n",
    "        out.outputs=();  f=FileLink(file)\n",
    "        with out:\n",
    "            display(f)\n",
    "            \n",
    "    def on_compress_scans(self,b):\n",
    "        '''\n",
    "        compress the currently available testing set.\n",
    "        '''\n",
    "        if len(self.scans_unclassified)<1: return\n",
    "        sp=ScanProcessor(self._classifier_model._scm)\n",
    "        compressed=sp.compress_scans(self.scans_unclassified)\n",
    "        fil='scans_compressed.csv'\n",
    "        self.write_scans_csv(compressed,fil)\n",
    "        self.show_file_link(self._dlraw_lnk,fil)\n",
    "            \n",
    "\n",
    "    def collect_scans(self,b):\n",
    "        with self._generate_output.out as o:\n",
    "            if self._verbosity>0:\n",
    "                print (self._rows)\n",
    "            subjs=[ s['Subject'] for s in self._rows ]\n",
    "            if self._verbosity>0:\n",
    "                print(\"len_subj\",len(subjs))\n",
    "            exps=[ s['Experiment'] for s in self._rows ]\n",
    "            if self._verbosity>0:\n",
    "                print(\"len_exps\", len(exps))\n",
    "\n",
    "            tags=self._classifier_model.get_selected_tags_group_element()\n",
    "            fields=self._classifier_model._scm.get_selected_fields_xnat()\n",
    "            if (self._verbosity>0):\n",
    "                print(tags)\n",
    "                print(fields)\n",
    "\n",
    "            self.scans_unclassified=self._xi.list_scans_in_experiments(subjs,exps,self._coll_status,\\\n",
    "                                                                    include_dcm_tags=tags,\\\n",
    "                                                         include_xnat_fields=fields,verbosity=2)\n",
    "\n",
    "            self.scans_unclassified_set=\"Collected from \"+list(self._fupl1_exp.value)[0]\n",
    "\n",
    "            self._coll_status='Status: found {} scans'.format(len(self.scans_unclassified))\n",
    "        #print(self.scans)\n",
    "        fil='all_scans.csv'\n",
    "        self._dlraw_btn.disabled=False\n",
    "        self._dlraw_lbl_current_file.value='Current dataset: collected scans'\n",
    "        self.write_scans_csv(self.scans_unclassified,fil)\n",
    "        self.show_file_link(self._out_lnk,fil)        \n",
    "    \n",
    "    def read_uploaded_file(self,b,status):\n",
    "        fupl=b\n",
    "        keys=list(fupl.value)\n",
    "        if self._verbosity>0:\n",
    "            print(keys,len(keys))\n",
    "        if len(keys)<1: return '',False\n",
    "        #try:\n",
    "        content_bytes=bytes(fupl.value[0].content)\n",
    "        csv_reader = csv.DictReader(io.TextIOWrapper(io.BytesIO(content_bytes)),skipinitialspace=True)\n",
    "        sp=ScanProcessor(self._classifier_model._scm)\n",
    "        self._rows=sp.uncompress_scans([{k: str(v) for k,v in row.items()} for row in csv_reader])\n",
    "        \n",
    "        #except:\n",
    "        #    status.value='cannot parse csv'\n",
    "        #    return False\n",
    "        \n",
    "        status.value='csv loaded with {} rows'.format(len(self._rows))\n",
    "        if self._verbosity>0:\n",
    "            print (len(self._rows))\n",
    "        #if self._fupl_drop.value=='scans-raw' or self._fupl_drop.value=='scans-classified':\n",
    "        #    self.scans=self._rows\n",
    "        #print(self._exps)\n",
    "        #print (list(fupl.value)[0])\n",
    "        return list(fupl.value)[0],True\n",
    "        \n",
    "    def clear_upload(self,fupl):\n",
    "        fupl.value = ()\n",
    "        fupl._counter=0\n",
    "        \n",
    "    def read_uploaded_file1(self,b):\n",
    "        _,res=self.read_uploaded_file(self._fupl1_exp,self._upl1_status)\n",
    "        self.clear_upload(self._fupl1_exp)\n",
    "        return res\n",
    "    \n",
    "    def read_uploaded_file2(self,b):\n",
    "        src,res=self.read_uploaded_file(self._fupl2_scans_unclassified,self._upl2_status)\n",
    "        if res: \n",
    "            self.scans_unclassified=self._rows\n",
    "            self.test_src=src\n",
    "            self._dlraw_btn.disabled=False\n",
    "            self._dlraw_lbl_current_file.value='Current dataset: uploaded'\n",
    "        self.clear_upload(self._fupl2_scans_unclassified)\n",
    "        return res\n",
    "    \n",
    "    def read_uploaded_file3(self,b):\n",
    "        src,res=self.read_uploaded_file(self._fupl3_scans_classified,self._upl3_status)\n",
    "        print(src,res)\n",
    "        if res: \n",
    "            self.scans_classified=self._rows\n",
    "            self.train_src=self.val_src=src\n",
    "            if self._verbosity>0:\n",
    "                print('train src:',src)\n",
    "        self.clear_upload(self._fupl3_scans_classified)\n",
    "        return res\n",
    "    \n",
    "    def write_scans_csv(self, scans, file):\n",
    "        with open(file, 'w') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, scans[0].keys())\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(scans)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalScanClassifierGUI(FrontDesk):\n",
    "    def __init__(self,data_selector,scan_classification_model):\n",
    "        ds=self._ds=data_selector\n",
    "        scm=self._scm=scan_classification_model\n",
    "        self._uc=UniversalScanClassifier(scm)\n",
    "        self.verbosity=0\n",
    "        \n",
    "        btn_lay={'width':'200pt'}\n",
    "        \n",
    "        self._current_model='None'\n",
    "        self._current_model_saved=False\n",
    "        \n",
    "        #1. load model gui.\n",
    "        self._load_lbl=ipw.Label(value='Upload model file (.pkl or .zip)')\n",
    "        self._load_btn=ipw.FileUpload(accept='.pkl,.zip',multiple=False)\n",
    "        self._load_btn.observe(self._on_load_model)\n",
    "        self._load_lbl_current_model=ipw.Label(value='Current model: None')\n",
    "        self._load_box=ipw.VBox([self._load_lbl,self._load_btn,\\\n",
    "                                    self._load_lbl_current_model])\n",
    "        \n",
    "        #2. Train model gui.\n",
    "        try:\n",
    "            trset=ds.train_src\n",
    "        except:\n",
    "            trset='None'\n",
    "            \n",
    "        self._train_current_set_lbl=ipw.Label(value='Current training set:{}'.format(trset))\n",
    "        self._train_lbl_current_model=ipw.Label(value='Current model: {}'.format(self._current_model))\n",
    "        #self._train_btn=ipw.Button(description='Train model',layout=btn_lay)\n",
    "        #self._train_btn.on_click(self._on_train_button)\n",
    "        self._train_output=ProcessWithTextProgress('Train model',self._on_train_button)\n",
    "        self._train_btn=self._train_output._btn_run\n",
    "        \n",
    "        self._train_save_btn=ipw.Button(description='Save trained model',layout=btn_lay,disabled=True)\n",
    "        self._train_save_btn.on_click(self._on_save_model)\n",
    "        self._train_lnk1=ipw.Output()\n",
    "        self._train_lnk2=ipw.Output()\n",
    "        self._train_box=ipw.VBox([self._train_current_set_lbl,self._train_lbl_current_model,\\\n",
    "                                 self._train_output.main_box,self._train_save_btn,\\\n",
    "                                 self._train_lnk1,self._train_lnk2])\n",
    "        \n",
    "        #3. validate model gui\n",
    "        try:\n",
    "            vset=ds.train_src\n",
    "        except:\n",
    "            vset='None'\n",
    "        \n",
    "        self._val_current_set_lbl=ipw.Label(value='Current validation set:{}'.format(vset))\n",
    "        self._val_lbl_current_model=ipw.Label(value='Current model: {}'.format(self._current_model))\n",
    "        #self._val_btn=ipw.Button(description='Validate model',layout=btn_lay)\n",
    "        #self._val_btn.on_click(self._on_validate_button)\n",
    "        self._val_output=ProcessWithTextProgress('Validate model',self._on_validate_button)\n",
    "        self._val_btn=self._val_output._btn_run\n",
    "        \n",
    "        self._val_box=ipw.VBox([self._val_current_set_lbl,self._val_lbl_current_model,\\\n",
    "                               self._val_output.main_box])\n",
    "        \n",
    "        #4. test model gui\n",
    "        try:\n",
    "            tset=ds.test_src\n",
    "        except:\n",
    "            tset='None'\n",
    "        self._tst_current_set_lbl=ipw.Label(value='Current testing set:{}'.format(tset))\n",
    "        self._tst_lbl_current_model=ipw.Label(value='Current model: {}'.format(self._current_model))\n",
    "        self._tst_btn=ipw.Button(description='Classify scans',layout=btn_lay)\n",
    "        self._tst_btn.on_click(self._on_test_button)\n",
    "        self._tst_lnk=ipw.Output()\n",
    "        self._tst_box=ipw.VBox([self._tst_current_set_lbl,self._tst_lbl_current_model,\\\n",
    "                                   self._tst_btn,self._tst_lnk])\n",
    "\n",
    "        #Main accordion.\n",
    "        titles=['Load a previously saved model','Train a model on the training set',\\\n",
    "                'Validate model on the validation set','Test model on the testing set']\n",
    "        \n",
    "        acc=ipw.Accordion(children=[self._load_box, self._train_box,\\\n",
    "                                    self._val_box,self._tst_box],selected_index=None)\n",
    "        for i in range(0,4): acc.set_title(i,titles[i])\n",
    "            \n",
    "        self.main_box=ipw.VBox([acc])\n",
    "                \n",
    "    def _on_load_model(self,b):\n",
    "        '''\n",
    "        Triggered when model files are uploaded\n",
    "        '''\n",
    "        fupl=self._load_btn\n",
    "        if len(fupl.value)<1: return\n",
    "        keys=list(fupl.value)\n",
    "        if self.verbosity>0:\n",
    "            print(keys,len(keys))\n",
    "        if len(keys)<1: return False\n",
    "        #try:        \n",
    "        model_nn=False\n",
    "        model_file=fupl.value[0].name\n",
    "        model_data=BytesIO(bytes(fupl.value[0].content))\n",
    "        with open(model_file,\"wb\") as f:\n",
    "            f.write(model_data.getbuffer())            \n",
    "        \n",
    "        if self.verbosity>0:\n",
    "            print('model file: '+model_file)\n",
    "        if os.path.splitext(model_file)[1]=='.zip': \n",
    "            if self.verbosity>0: print('neural net model selected')\n",
    "            model_nn=True\n",
    "        \n",
    "        \n",
    "        if model_nn:\n",
    "            if not self._uc.load_model_nn(model_file):\n",
    "                print('Error loading model '+model_file)\n",
    "                return\n",
    "        else:\n",
    "            if not self._uc.load_model(model_file):\n",
    "                print('Error loading model '+model_file)\n",
    "                return\n",
    "                \n",
    "        self._current_model='{}'.format(os.path.basename(model_file))\n",
    "        self._current_model_saved=True        \n",
    "        self.refresh()    \n",
    "    \n",
    "    def _on_train_button(self,b):\n",
    "        '''\n",
    "        Runs when 'Train' button is clicked\n",
    "        '''\n",
    "        uc,scans=self._uc,self._ds.scans_classified\n",
    "        #1. generate vocabulary\n",
    "        with self._train_output.out:\n",
    "            uc.init_and_run_nn_training(scans)\n",
    "            \n",
    "        self._current_model='{}_{}_{}'.format(self._scm._nomenclature_name, self._ds.train_src,\n",
    "                                                  datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "        if self.verbosity>0:\n",
    "            print('current model: ',self._current_model)\n",
    "        self._current_model_saved=False\n",
    "        self.refresh()\n",
    "    \n",
    "    def _on_save_model(self,b):\n",
    "        #print('on_save_model triggered')\n",
    "        self._uc.save_model_nn(self._current_model+'.zip')\n",
    "        self._current_model_saved=True\n",
    "        self.show_file_link(self._train_lnk1,self._current_model+'.zip')\n",
    "        \n",
    "    def _on_validate_button(self,b):\n",
    "        '''\n",
    "        Runs when 'Validate' button is clicked\n",
    "        '''\n",
    "        tscans=self._ds.scans_classified\n",
    "        with self._val_output.out:\n",
    "            classified_types=self._uc.infer_nn(tscans)\n",
    "            n=0\n",
    "            for i in range(len(tscans)):\n",
    "                \n",
    "                if classified_types[i]!=tscans[i]['hof_id']:\n",
    "                    print('position: {}, predicted: {}, actual: {}'\\\n",
    "                          .format(i,classified_types[i],tscans[i]['hof_id']))\n",
    "                    n+=1\n",
    "            print('Classification accuracy:',1.-n/len(tscans))\n",
    "            print(\"Done.\")\n",
    "        \n",
    "    \n",
    "    def _on_test_button(self,b):\n",
    "        '''\n",
    "        Runs when 'Test' button is clicked        \n",
    "        '''\n",
    "        tscans=self._ds.scans_unclassified\n",
    "        classified_types=self._uc.infer_nn(tscans)\n",
    "        for scan,ct in zip(tscans,classified_types):\n",
    "            scan['hof_id']=ct\n",
    "        tempfile=re.sub('[^0-9a-zA-Z]+', '_', 'classified_scans_{}.csv'.format(str(datetime.datetime.now())))\n",
    "        self._uc.write_scans_csv(tscans,tempfile)\n",
    "        self.show_file_link(self._tst_lnk,tempfile)\n",
    "        \n",
    "    def refresh(self):\n",
    "        if self.verbosity>0:\n",
    "            print('refresh')\n",
    "        self._train_current_set_lbl.value='Current training set: {}'.format(ds.train_src)\n",
    "        self._val_current_set_lbl.value='Current validation set: {}'.format(ds.train_src)\n",
    "        self._tst_current_set_lbl.value='Current testing set: {}'.format(ds.test_src)\n",
    "        \n",
    "        self.enable_nav_prev(True)\n",
    "        model_saved=\"saved\" if self._current_model_saved else \"unsaved\"\n",
    "        model_loaded=self._current_model!=\"None\"\n",
    "                \n",
    "        cm=\"Current model: {} ({})\".format(self._current_model,model_saved)\n",
    "        self._load_lbl_current_model.value=self._train_lbl_current_model.value=\\\n",
    "                self._val_lbl_current_model.value=self._tst_lbl_current_model.value=cm\n",
    "        \n",
    "        #enable Train and Validate buttons if classified scans are loaded\n",
    "        self._train_btn.disabled=not len(self._ds.scans_classified)>0\n",
    "        self._val_btn.disabled=not(model_loaded and len(self._ds.scans_classified)>0)\n",
    "        self._tst_btn.disabled=not(model_loaded and len(self._ds.scans_unclassified)>0)\n",
    "        \n",
    "        \n",
    "        #print('_current_model_saved:',self._current_model_saved)\n",
    "        #print('_current_model:',self._current_model)\n",
    "        #print('model_saved:',model_saved)\n",
    "        #print('model_loaded:',model_loaded)\n",
    "        \n",
    "        #print('train_save_btn.enabled',not self._current_model_saved and model_loaded)\n",
    "        self._train_save_btn.disabled=self._current_model_saved\n",
    "                            \n",
    "    def show_file_link(self,out,file):\n",
    "        out.outputs=();  f=FileLink(file)\n",
    "        with out:\n",
    "            display(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ab9aef56c141efbed27654d6e389e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Classifier model</h4>'), VBox(children=(VBox(children=(Text(value='NeuroOncologâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scm_gui=ScanClassificationModelGUI()\n",
    "ser_file='universal_scan_classifier_params.json'\n",
    "ds=DataSelector(ser_file,scm_gui)\n",
    "sc_gui=UniversalScanClassifierGUI(ds,scm_gui._scm)\n",
    "\n",
    "#debug\n",
    "ds._xi._verbosity=2\n",
    "ds._verbosity=2\n",
    "\n",
    "pages=[\n",
    "    {'title':'Classifier model','frontdesk':scm_gui,'plumbing':None,'prev_label':None,'next_label':'Training set'},\n",
    "    {'title':'Dataset preparation','frontdesk':ds,'plumbing':None,'prev_label':'Classifier model','next_label':'Training/testing'},\n",
    "    {'title':'Training/testing','frontdesk':sc_gui,'plumbing':None,'prev_label':'Dataset preparation','next_label':None}\n",
    "]\n",
    "\n",
    "g=GUIBook(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
